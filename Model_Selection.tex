\documentclass[a4paper,12pt]{article}

\usepackage{epsfig}
\usepackage{fullpage}
\usepackage{amsmath, amssymb, amsthm} % AMS packages
\usepackage{textcomp}
\usepackage{color}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{setspace}
\definecolor{gray}{gray}{0.5}

\newcommand{\mcr}[1]{\par\medskip\noindent\fbox{\parbox{\textwidth}{\textbf{Comment by MC}: #1 }}\medskip}
\newcommand{\spp}[1]{\par\medskip\noindent\fbox{\parbox{\textwidth}{\textbf{Comment by SPP}: #1 }}\medskip}
\newcommand{\degree}{\ensuremath{{}^\circ}}

\newcommand{\rdw}[1]{\par\medskip\noindent\fbox{\parbox{\textwidth}{\textbf{Comment by Rich}: #1 }}\medskip}

\newcommand{\etal}{{\it et al. }}


\title{Model selection is possible with palaeoclimate data and models of the glacial-interglacial cycle\\
What drives the glacial-interglacial cycle? A Bayesian approach to a long-standing problem}
\author{Carson, Crucifix, Preston, Wilkinson }

\begin{document}
\maketitle 
\mcr{We'll probably have to think about the title but that's not urgent}

%\doublespacing

\begin{abstract}

The prevailing viewpoint in palaeoclimate science, is that a single palaeoclimate record   contains insufficient information to  discriminate between  most competing  explanatory models.
Our aim here is to show  that this is not the case. Recent developments in Monte Carlo methodology, combined with advances in computer power, mean that for a wide class of phenomenological models, we are now able to perform filtering, calibration, and Bayesian model selection.
Using the SMC$^2$ algorithm of Chopin \etal 2014, combined with Brownian bridge proposals for the state trajectories, we show that even with relatively short time series, it is possible to estimate Bayes factors to sufficient accuracy to be able to select between competing models. 
%This suggests a new possibility for those working in climate science - careful empirical comparison of competing hyptotheses is now possible....

Our results highlight the problem of using pre-dated palaeoclimate records. By analysing a dataset that has been dated by two different authors, we reach contradictory conclusions, thus indicating that the current practice of first dating a record, and then analysing it to draw scientific conclusions about the dynamics of the system in an independent analysis is ....We conclude that  dating and analysis should be done in a single process....


\end{abstract}



\section{Introduction}

\rdw{This is not a modelling or a science paper. It is a proof of concept: we can do model selection. Give us your models and your data, and we can say which is best supported.}


The history of the Earth's climate can be reconstructed from different sources, 
including, among others, fossil organisms found it deep-sea sediments (REF : Hillaire-Marcel and 
De Vernal). Foraminefera are one such class of organisms. 
The ratio between oxygen isotopes $^{18}O$ and $^{16}O$ measured in their calcite shells
reflects a combination of effects associated with changes in ocean temperature and sea-level 
\cite{emiliani55, shackleton67}. 
This quantity is classically expressed in the form of quanted called the $\delta^{18}O$, which defined as the relative 
difference between the measured isotopic ratio and a standard reference.
Broadly speaking, larger values of $\delta^{18}$O 
indicate a colder climate with greater ice volume.
Used jointly with other informations, $\delta^{18}$O extracted provide a consistent picture of the Earth's recent glaciations.
That first indices of Northern Hemisphere glaciation since the beginning of the Cenozoic appeared  about 3 million
years ago \cite{Shackleton84ab}. This event roughly coincides with the beginning of the Pleistocene epoch. 
Throughout the Pleistocene climate then fluctuated between cold periods, in which glaciers expanded, and warm
periods in which the glaciers retreated, following a cycle that is approximately 40,000 years long. 
Around 1 Mya ago, the average period increased to approximately  100 kyr, a change in behaviour known as
the mid-Pleistocene transition \cite{Ruddiman86}. 

It is generally admitted that glacial-interglacial cycles are driven or at least partly controlled
by gravitationnal effects associated  with the shape and movement of the Earth, the Moon, and other planets 
around the Sun.
These effects translate, among others, into variations in 
the angle between the equator and the orbital plane that affect the distribution of incoming solar radiation (insolation)
accross seasons and latitudes. This angle is called the obliquity ($\varepsilon$). 
The other important astronomical effect to be accounted for is
the precession of the point of shortest Earth-Sun distance with respect to the vernal point marking the Spring
equinox (quantified with the angle $\varpi$ made by the two points around the sun).
Considering that perihelion is a time when the Earth anomalously close to the Sun compared to a circular orbit, one observes that
the precession of $\varpi$ cause positive / negative anomaly insolation patterns, sequentially accross the different months of the year. The full cycle takes
approximately 23,000 years. The amplitude of this effect is further modulated by changes
in eccentricity $e$ expressing the shape of the Earth's orbit. Palaeoclimatologists often refer to the synthetic quantity $e\sin\varpi$
a useful synthetic descriptor of the combined effects of changes in $\varpi$ and $e$. This quantity is called the climatic precession parameter. 

These astronomical effects have been known and suspected to play a role on ice ages since the XIXth century. In  particular, their effects on the snow-line controlling the growth and shrink of ice sheets were first mathematically modelled by Milutin Milankovitch (\cite{milankovitch41_original}; translation in \cite{milankovitch41})

The theory of planetary motion is now advanced to the point that the time evolution of the astronomical forcing can be computed to any reasonable accuracy over the full Pleistocene \cite{Berger1978a, Laskar04aa}. In particular, it is known that the variations of obliquity are quasi-periodic and dominated by a period of 41,000 years that matches the periodicity of Early Pleistocene climate changes. This suggests a causal mechanism between astronomical forcing and climate, and physical modelling of the ice sheets does confirm, indeed, that astronomical forcing would be sufficient to cause sigificant ice sheet variations (e.g. \cite{Abe-Ouchi13aa} for a recent account, and ref. therein). 

However, mere inspection of the astronomical forcing history would not yield any straigtforward explanation of the Mid-Pleistocene transition, nor does it explain the 100,000 year average period of ice ages since this transition. Admittedly, the spectrum of eccentricity contains much power around 100,000 years \cite{Berger1978a} as well as in other functions of astronomical parameter \cite{Berger05aa}, but local measures of insolation \cite{Hays1976} have so to say no power anywhere near 100,000 year. This paradox is sometimes referred to in the climate science literature as the 100,000-yr mystery \cite{Ruddiman06aa}. 
In fact, although the average duration of late Pleistocene ice cycle was at first unexpected, it should
 not be surprising to find long periods in such a  complex system as Earth's climate. After all, astronomical forcing
is just an input in a system that may contain all sorts of eigen modes of motion. 

Our understanding of the climate system history therefore depends on the successful  
articulation of different models with the 
the data at our disposal. Some of the models are very complicated, and include numerous
physical processes. Their purpose is investigate and quantify plausible physical mechanisms
in the Earth's climate response. Other models are much simpler and sometimes featuring 
only a couple of differential equations possibly combined with time-stochsatic processes.
The latter are used as a framework to investigate dynamical effects associated
with the emergence and stability of glacial cycles. 
Within this restricted framework of low-order dynamical systems, 
different models may be found to fit the data reasonably well, 
yet displaying different proporties  or bifuraction structures
(see \cite{Crucifix2013, DitlevsenXX} for a recent account).
It is a common viewpoint is that the  information contained in a single proxy record is not
sufficient  to distinguish between the numerous proposed models
\cite{Cane2006,Roe1999}.

The aim of this paper is then rather to demonstrate that this is not the case and that \mcr{aren't we a bit strong here ?}  empirical evaluation of  candidate dynamical models is possible, including assessing the importance of the various orbital characteristics to the glacial-interglacial cycle.
By treating the problem as a model selection problem with unknown parameters, we are able to estimate Bayes factors and analyse the problem in a fully Bayesian manner,  determining which model best explains the  data, as well as estimating the  parameters for each model.

The statistical challenge
 is to make 
inferences using partially observed, forced,
non-linear stochastic differential equations (SDEs). The two major challenges in SDE inference are  that the transition density, and therefore the likelihood function, is not
available is closed form, and that the state trajectory is a high dimensional unobserved component that must be imputed in any Monte Carlo algorithm.
 A powerful tool for time-structured problems with intractable likelihoods is the particle
filter, and in this paper we employ the  SMC$^2$ approach recently
introduced by \cite{Chopin2012}, which is a pseudo-marginal algorithm that embeds a particle filter within a sequential Monte Carlo algorithm to do joint state and parameter estimation. A major advantage of SMC$^2$ over  competitor methods, such as particle MCMC \cite{Andrieu2010}, is that it allows for easy estimation of the model evidence. We exploit this to provide estimates of the Bayes factors. 

A naive implementation of SMC$^2$ fails due to extreme particle degeneracy. We show how guided Brownian bridge proposals can be used to maintain particle diversity with evenly distributed weights. When efficiently parallelised on a GPU, this allows inference to be performed in reasonable time (3-4 days for the results in Secion \S??). A surprising result is that even though the Monte Carlo error in our Bayes factor estimates is large, the Bayes factors are sufficiently large, even for short time-seroes of data, that we can still distinguish between the competing models.


Before formulating further the statistical problem, we briefly review earlier research that
investigated the role of the orbital characteristics on the glacial--interglacial cycle.
Several papers develop frequentist hypothesis tests
\cite{Huybers2005,Lisiecki2010,Huybers2011}, based on comparing ``termination times'', which
mark where individual glacial cycles finish, with the times of the maxima of the insolation
function.  In \cite{Huybers2011}, for instance, the null hypothesis, $H_0$, is that the
termination times are independent of the timings of the maxima for a given insolation
function, and the alternative hypothesis, $H_1$, that the terminations tend to occur when
the maxima are anomalously large.  The test statistic used is the difference between the
medians of the forcing maxima associated with terminations and with those not associated
with maxima, with the null distribution generated from random simulations of termination
times under a model consistent with $H_0$.  Such an approach leads to a $p$-value that
characterises the strength of evidence against $H_0$ for a given insolation function.  
As always with such frequentist approaches the interpretation of $p$-values requires care: a
``non-significant'' $p$-value reflects that the data provide insufficient evidence to reject
$H_0$ in favour of $H_1$, not that $H_0$ should be favoured over $H_1$.  (This is in
contrast to the Bayesian approach which we adopt in this paper, in which evidence for
competing hypotheses can be directly compared.) 

\mcr{won't we need another read of the Huyber 2004 ? I vaguely remembre that they also try to
reject H1}

Moreover, differences in the details about
how the foregoing frequentist tests are constructed substantially effect the conclusions,
with different studies finding different orbital characteristics being significant
(obliquity in \cite{Huybers2005}, eccentricity in \cite{Lisiecki2010}, and a combination of
precession and obliquity in \cite{Huybers2011}).

\spp{JAKE: We need a para here about the Phil Trans paper comparing models using information
criteria}

This paper is structured as follows.  In Section \ref{Sec:Data} we describe in more detail the
$\delta^{18}O$ dataset on which we will base inference, and we detail the
models we consider for astronomical forcing, for the Earth's climate 
dynamics, and for the observations.  Section
\ref{Sec:Meth} includes a formulation of the Bayesian approach and brief review of the
particle-filter methods that we extensively use.  In Section \ref{Sec:Results} we present 
a simulation study to assess the performance of the algorithms on synthetic data, and an  
analysis of the real $\delta^{18}O$ dataset.  In Section \ref{Sec:Conclusion} we offer
some thoughts on the practical implementation of the particle-filter methods for such
problems, discuss the scientific conclusions, and suggest some future directions for
research.

 \spp{I agree with
  MC's comment that such discussion would be helpful there and should fit well in RSSC -
certainly more so than attempts to make scientific conclusions which might sound
overstretched}


% Previous work has typically used frequentist hypothesis testing.  Usually the
% palaeoclimate data is summarised as a series of `termination times', which mark the end
% of individual glacial cycles \cite{broecker70}.  An orbital parameter is considered
% influential if some measure (i.e.  phase, amplitude) of its variability is significantly
% correlated to the termination times.  An orbital parameter is not ruled out if the
% amount of correlation is insignificant; one can only say that there is insufficient
% evidence to determine whether or not the orbital parameter is influential.  The success
% of these experiments depend upon their design, with different experiment designs showing
% positive results for 


\color{black}
\section{Data and models}
\label{Sec:Data}

Our approach to understanding the dynamical behaviour of the palaeoclimate involves four components: data consisting of palaeoclimate records;  models of the climate;  drivers/forcings of the climate (such as CO$_2$ emissions, or more pertinently for palaeoclimate, the astronomical forcing), and  a statistical model relating the three previous components.

The aim of the paper  is  to demonstrate  the statistical methodology necessary for combining these components in order to answer the questions we imagine palaeoclimate scientists may wish to ask. That is to say, given some data and a selection of models, we show how to fit these models, and to assess which model is best supported by the data. Scientific aspects of the approach can (and we hope will) be improved upon by using different datasets, richer models, and a more realistic statistical framework. Here, our aim is mainly to show that the methodology and computing power is now of sufficiently advanced state that the Bayesian machinry for inference can be applied and that it is fruitful to do so.

\rdw{Michel - I was aiming to describe the holy trinity diagram you used in Uccle (the triangle of approaches) with the aim of unifying some of them using stats. Its kind of an apologia to stress that this is a proof of concept of the stats.}



\subsection{Data}

\rdw{Jake: do we just use sediment? In which case, some of this discussion can have ice removed}.

The data we will use are based on measurements of $\delta^{18}O$ at different depths in sediment.
In
climatology, a set of such measurements is known as a ``record'' [?], and an average
over multiple records  is known as a ``stack''.  The $\delta^{18}O$ in deeper parts of a
core correspond to climate conditions further back in time.  Beyond monotonicity,
there is unfortunately no simple relationship between core depth and age.  This is because the
accumulation of sediment  results from a combination of 
complicated physical processes
including sedimentation (which occurs at variable rates), erosion, and core
compaction.  A model for the relationship between depth and age is known as an ``age
model'', and many such models have been proposed in the literature [refs].  
A common stategy in developing an age
model is to align features of records to important events, such as magnetic reversals,
whose dates are accurately known from other sources.  Also common is to align features to aspects of the
astronomical forcing [refs], a process known as astronomical tuning.  
The result of fitting an age model is a dataset $\left\{ \tau_t, Y_t\right\}$ in which $Y_t$ denotes the measurement of $\delta^{18}O$ at time $\tau_t$.  
Investigating age 
models is beyond the scope of this paper, so we take as a starting point a stack  which has been dated by other authors. Estimating $\tau_t$ is complex and covered in depth in \cite{???}. Here, in common with most other studies, we treat $\tau_t$ as a given. We comment on the wisdom of this approach in Sections \S.
\rdw{Should we say something about uncertainty on $\tau_t$ and that we're ignoring it? Perhaps leave this to the conclusion.}



In this article, we use 
the ODP677 record \cite{Shackleton1990}, shown in Figure~\ref{Fig:Data}.
ODP677 has been dated both as part of an orbitally tuned scheme \cite{Lisiecki2005}, and a non-orbitally tuned scheme \cite{Huybers2007}. Orbitally tuned data are undesirable when studying the influence of the astronomical forcing, as the forcing itself would be double counted.
Any results suggesting a strong influence from the astronomical forcing may in fact be highlighting the dating assumptions.
It is therefore preferable to use data which has not been orbitally tuned in model selection and, in particular, estimate the influence of astronomical factors on the dynamics of the glacial-interglacial cycle.
  We focus on the last 780 kyr of this record (the last magnetic reversal occured 780 kya, allowing us to date the starting point accurately), which contains 363 observations, and use it to highlight the issues surrounding double counting of the astronomical forcing.





\begin{center}
\begin{LARGE}
Figure \ref{Fig:Data} about here.
\end{LARGE}
\end{center}


%\spp{Anything alse needed from below?}
%
%\color{gray}
%

%Datasets from individual drill sites typically contain observations that are noisy, and sparsely distributed in time.
%Geological conditions can also lead to incomplete records, where there are large lengths of time with no observations, and repeated data, where the same events can be identified numerous times in a single record.
%These problems have motivated the development of stacks \cite{Lisiecki2005,Huybers2007}.
%A stack is a composite of multiple records, which are correlated and averaged over to give a single complete dataset with an improved signal-to-noise ratio.
%By using records from numerous sites, stacks are also more likely to represent global conditions, as local variation is averaged out.
%However, the averaging methods typically employed can lead unprincipled inference as it is not clear how the particular averaging scheme used has altered the information for each record.

%On the other hand, 
%converting the depth scale of sediment and ice-cores into a time scale is non-trivial.
%There are very few points in the sediment cores that can be dated confidently, using either biostratigraphic markers or identified magnetic reversals. Namely, the most recent magnetic reversal is the Bruhnes-Matuyama event 780 kyr BP. However, variations in sedimentation rates, down-core compaction, and numerous other physical processes imply that observation times do not change linearly through the core.
%The study of the age-depth relationship and age-depth uncertainty has led to numerous proposed age models.
%By far the most common approach is to align features of the astronomical forcing to the record of interest; a process known as orbital tuning.
\color{black}

\subsection{The astronomical forcing}

The amount of insolation hitting the top of the atmosphere at any point on Earth 
is a function of the hour angle (time in the day), the latitude and the true solar longitude (i.e., time in the year), 
as well as of three parameters that vary on much longer time scales : the longitude of the perihelion ($\varpi$), 
the obliquity ($\varepsilon$), and eccentricity. 

Insolation can thus be computed at any point of Earth for anytime. 
However, as we are concerned here with phenomenological models, we need to rely 
on some subset summary of the seasonal and spatial distributions of insolation on climate.
To this end, it is common to refer to  Milankovitch's theory, which asserts that the growth and shrinking of ice sheets is controlled by summer insolation.
Specifially, Milankovitch considered a particular descriptor which he termed the caloric summer insolation: this is
the amount of energy received at the top of the atmosphere during the half of the year that gets the largest amount of insolation, typically
at a reference latitude of 60\degree N. Other common descriptors include the daily-mean insolation at summer solstice at 60$\degree$N \cite{imbrie80}
or at different times in the year \cite{Saltzman1990}. In fact, all these descriptors may generally be expressed as a linear combination of three parameters: 
the obliquity $\varepsilon$, the climatic precession parameter $e\sin\varpi$ and its complement  $e\cos\varpi$.
Obliquity  controls the seasonal contrast symetrically
in both hemispheres, as well as the pole-equator gradient of annual mean insolation \cite{Loutre04}. 
The quantity $e\sin\varpi$ is a proxy for the effect of precession on summer insolation in the northern hemisphere. Indeed, 
the summer solstice in the Northern Hemisphere occurs when the true solar longitude is $\pi/2$. Insolation anomalies induced by   precession
are thus largest when perihelion occurs at that true solar longitude,  i.e., $\varpi = \pi/2$. Similarly, $e\cos\varpi$ is a proxy
for the precession effect on spring insolation, and the precession effect on any given month of the year can be obtained by suitable combination
of these two quantities. 

To summarise, a general model could include the astronomical forcing as a linear combination of $e\sin\varpi$, $e\cos\varpi$ and $\varepsilon$. 
\cite{Berger1978a} provides an algorithm to compute these quantities with sufficient accuracy for the Pleistocene. Note that :\cite{Laskar04aa} provides more accurate, time-indexed tables

computed from symplectic numeric integration of relativist celestial mechanics, but the gain in accuracy is not critical in this context. 

A last point need to be said about the forcing. By reasoning on the geometry of ice sheets and snow line it is possible to see that a positive insolation anomoly may proportionnally be more effecient 
on ice volume change, than a negative one \cite{oerlemansXX, Ruddiman06aa}. To account for these effects 
some authors apply a truncation operator to the astronomical forcing in order to downweight
negative anomalies. In particular, \cite{paillard98} and \cite{Parrenin2012} introduce the function $f$ as follows:
\[ f(x) = \left\{
  \begin{array}{l l}
    x + \sqrt{4a^2 + x^2} - 2a & \quad \text{if $x > 0$}\\
    x & \quad \text{otherwise}
  \end{array} \right.
\]
 
\mcr{ Need to summarise by introdcing $F(\gamma_P, \gamma_C, \gamma_E)$ used below. }

%The insolation at 65\textdegree N on  the summer solstice is recovered by setting $\gamma_P=0.8949$, $\gamma_C=0$ and $\gamma_E=0.4346$.


\subsection{Phenomenological models of climate dynamics}

We consider three models for the climate dynamics. They were each originally proposed as low order ordinary differential equations, with state vector $x$ where the first component $x_{(1)}$ represents  global ice volume. The other
components represent other quantities such as  glaciation state or CO$_2$ concentration. In order to account for model errors, we convert the models into stochastic differential equation by the addition of a Brownian motion $W_t$.  Each model models the glacial-interglacial cycle
using a qualitatively different dynamical mechanism, as explained further below.  
%For an overview of oscillators in palaeoclimate modelling see \cite{Crucifix2012}).

\subsubsection*{Model SM91: Saltzmann and Maasch (1991)}
\begin{eqnarray*}
dX_{(1)} & = & -\left( X_{(1)} + X_{(2)} + v X_{(3)} + F(\gamma_P,\gamma_C,\gamma_E) \right)dt + \sigma_1 dW_{(1)} \\
dX_{(2)} & = & \left( r X_{(2)} - p X_{(3)} - s X_{(2)}^2 - X_{(2)}^3 \right)dt + \sigma_2 dW_{(2)} \\
dX_{(3)} & = & -q \left( X_{(1)} + X_{(3)} \right) dt + \sigma_3 dW_{(3)}
\end{eqnarray*}
This models glacial--interglacial cycles as system of three differential equations associated with Brownian motion. 
Variables $X_{(2)}$ and $X_{(3)}$ respectively represent 
CO2 concentration in the atmosphere,  and deep-sea ocean temperature.  
The model exhibits limit-cyle dynamics : it is therefore
an oscillator generating a periodicity around 100,000 years, and which is further controlled by the astronomical forcing. 
The model was meant as an expression of the hypothesis that
carbon-cycle effects are critical for the emergence of glacial cycles.
Hence non-linear terms, responsible for the oscillation, are present in the second equation only.


\mcr{  
As we  will only be assessing the model on the basis of observations of  the first component,  we can be incomfortable in drawing conclusions
on the correctness of the identification of
$X_2$ as CO2 and $X_3$ as ocean temperature.  Only physical modelling and understanding would allow to identify those variables to physcial quantities. Indeed, we 
could claim that $X_2$  only  if we had strong physical reasons to say that this equation 2 is indeed the right equation for CO2, and likewise for deep ocean temperature. Physical constraints
may further be introduced in the prior. Unfortunately, we can't  really claim this. Saltzman's model  was very speculative and in fact if I were to vote today I would
probably advocate swapping the labels (i.e. call $X_2$ temp. and $X_3$ CO2). It 's all a bit tricky and I am unsure of how to clarify this without distracting the audience and lose its attention on methodology. }

Example trajectories are shown in Figure [? - comment].

\subsubsection*{Model T06: [authors, year] }
\begin{eqnarray*}
dX_{(1)} & = & \left( \left(p_0 - K X_{(1)} \right) \left(1 - \alpha X_{(2)} \right) - \left(s + F(\gamma_P,\gamma_C,\gamma_E) \right) \right) dt + \sigma_1 dW_{(1)} \\
  X_{(2)} & : & \mbox{ switches from } 0 \mbox{ to } 1 \mbox{              when $X_{(1)}$ exceeds some threshold $T_u$} \\
  X_{(2)} & : & \mbox{ switches from } 1 \mbox{ to } 0 \mbox{              when $X_{(1)}$ decreases below $T_l$}
\end{eqnarray*}

This is an example of a ``hybrid'' model coupling $X_{(1)}$, which is governed by a stochastic differential equation, 
to a binary indicator variable $X_{(2)}$. 
When $T_u$ and $T_l$ are suitably chosen the resulting dynamics are a relaxation oscillation: $X_{(1)}$ is trending upwards or downwards depending on the state of  $X_{(2)}$, and reverses trend as a threshold changing the state of $X_{(2)}$  is being approached. Just as in SM91, the oscillation is further controlled by the effect of astronomical forcing, allowing for synchronisation effects \cite{Tziperman2006}. 
The purpose of the authors detailed in some of their publications prior to \cite{Tziperman2006} was originally to suggest a critical role for Arctic sea-ice cover : a positive sea-ice cover anomaly reduces the amount of snow fall on northern hemisphere ice caps, thereby acting \textit{negatively} on the growth of ice (hence the $- X_{(2)}$ term in the equatino for $dX_{(1)}$), and vice-versa. However, the objective of the particular article by \cite{Tziperman2006} was also to emphasise that different mechanistic  (dynamical?) interpretations could equally lead to relaxation oscillations. 

[Description of params].  Figure [] shows examples trajectories [comment].

\subsubsection*{Model PP12: [authors, year]}

\spp{We need the notation here to make clear what this has in common with T06.  I've tried this below.  But I could
only go so far as the defns of the various quantities seem quite arbitrary.  What is the physical interpretation of the
scaling and truncation of the forcing?  *The defn needs checking* }

\begin{eqnarray*}
  dX_{(1)} &= &-(\gamma_P \Pi^{\dag} + \gamma_C \tilde{\Pi}^{\dag} + \gamma_E \bar{O} - a_g + (a_g+a_d+X_{(1)}/\tau)X_{(2)})dt + \sigma_1 dW_{(1)}, \\ 
  X_{(2)} & : & \mbox{ switches from } 0 \mbox{ to } 1 \mbox{ when $F(\kappa_P,\kappa_C,\kappa_E)$ is less than some
threshold $v_\text{l}$} \\
X_{(2)} & : & \mbox{ switches from } 1 \mbox{ to } 0 \mbox{ when  $F(\kappa_P,\kappa_C,\kappa_E) + X_{(1)}$ is greater than some $v_\text{u}$}
\end{eqnarray*}
where $\Pi^{\dag}$ and $\tilde{\Pi}^{\dag}$ are transformed precession and coprecession components defined as 
\spp{needs
explanation as this seems totally arbitrary! Could we move the forcing description to the previous section, so that it is presented as some transformation of $F$ from before, to keep the separation of models from forcings?}

\mcr{ The truncation is now explained above. As the scaling concerns, in fact these are just the numbers needed to scale it such that these quantities have variance 1 in order to match PP12. This said, we could chose \textit{not} to scale, and just write ($f(\Pi)$), and redefine the parameters accordingly. It will read better, but we lose the compatibility with the notation introduced by the authors and also requires a reprocessing of our output. }


\begin{eqnarray*}
  \Pi^{\dag} & = & (f(\bar{\Pi}) - 0.148) \diagup 0.808 \\
\tilde{\Pi}^{\dag} & = & (f(\bar{\tilde{\Pi}}) - 0.148) \diagup 0.808,
\end{eqnarray*}
with $f$ is the truncation operator defined in section XX. 

  This is also a hybrid model with $X_1$ governed by an SDE and with $X_2$ a binary variable. In this model 
  represents a hidden climatic state, that may either be ``glaciation" (0) or ``deglaciation" (1). Such distinction of 
  climatic states finds empirical justification in the data analysis by \cite{Imbrie11aa} : 
  during the glaciation phase ice volume trends upwards and is linearly controlled by the truncated insolation. 
  The deglaciation phase is simply a relaxation towards low ice volume. One crucial assumption of this model is that the 
  the deglaciation - glaciation switch is conditioned by insolation alone (this may be counter-intuitive), 
  and the glaciation-deglaciation swith is determined by a condition on glaciation and insolation.  This contrasts with T06 where the 
  state changes are determined only by the system state. Consequently, a constant forcing cannot induce spontaneous oscillations in PP12. 
  \mcr{The more I think of this model, the more I get some uneasy feeling. If I were a Bayesian gambler, I would definitely downweight PP12
  before starting to play, because I struggle to give physcial sense to the interglacial-glacial thershold. I would give it a low prior, and
  need  very strong positive evidence to accept it}
  Example trajectories are shown in Figure [] [comments]

\rdw{Jake: Can you add the references back that have been list in the editing.}

\mcr{It is probably too late to come with such a comment, but we should keep in mind that, after all, what we compare here are essentially three oscillators linearly forced by the astronomical forcing, albeit with some nuances. For example we did not consider  radically different models, that e.g. would not include the astronomical forcign but another forcing function (the orbital plane hypothesis), as Roe and Allen did. The reviewer might complain about the fact that we are comparing three eggs, while we 'd better consider a lemon, and orange and an egg, especially if the truth is in fact an apple.  One thing we could do, though, is to sample the priors and provide predictions of the 'natural' evolution of the Holocene up to +100 ka, and see whether the models provide significant different predictions and/or interglacial lengnths}.

\subsection{Statistical observation model}

The final modelling ingredient is a statistical model relating the unobserved state
variables in the dynamical models,  $X_t$, to the  dataset.  We assume that the data are of the form $\left\{ \tau_t, Y_t\right\}_{t=1}^T$, where $\tau_t$ is the estimated age and $Y_t$ the measured proxy of the $t^{th}$ data point/slice. 
We use the model
\[ Y_t \sim \mathcal{N} ( d + H X_{1t}, \Sigma_y^2), \]
Here we use $H=(s, 0,\ldots, 0)$, so that $Y_t$ is a scaled and shifted
version of the value $X_{(1)t}$, the ice volume in the underlying dynamical model. However, vector observations can be used at no additional cost or complication to the methodology, allowing us to add in observations of other proxies if desired.


This is the measurement process, which relates true $\delta^{18}O$ to measured  $\delta^{18}O$. The second part of the statistical specification is the model discrepancy. This describes the relationship between the imperfect dynamical model and true climate. To account for this error, we have added a white noise term to the models as described above. More complex discrepancy models may be sensible \cite{Kennedy2001, Wilkinson2011}, and in particular, red noise may be a more appropriate choice. \rdw{Michel: do we have a reference for this?}
\mcr{no\ldots and that's the problem. I believe this is a fundamental issue that we have considered exploring but for which I do not know any reference. What are the kennedy and wilkinson2011 papers ?}

\rdw{I've added the $\tau_t$ notation as a way to emphasise that the ages are estimates, and that $t$ usually refers to an index, rather than a time. I'm not sure I like it yet though.}

\spp{Is this ``scalar'' version general enough for the paper?  We need to sort out
notation (currently $X_1$ variously denotes first element of vector X, scalar X evaluated at t=1,
and scalar X evaluated at first time index) - need to talk about this before making a
decision.}

\rdw{Jake:  Simon has changed $D -> d$, and  $h -> s -> H$. I'm not sure I like this. The change will either need reversing or  following through. I think Simon's reasoning for changing to d and h, is that its easier to present the method for 1d observations, in which case a lower case letter may make more sense. }


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
% Methodology
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage
\color{black}
\section{Methodology}
\label{Sec:Meth}

Our primary aim is model selection: given a collection of competing models $\{\mathcal{M}_m\}_{m=1}^M$ of dataset $y_{1:T}$, which is best supported by the data? 
The Bayesian approach to model selection uses Bayes factors (BF) \cite{Jeffreys1939, Kass1995}. The BF for comparing two models, $\mathcal{M}_1$ and $\mathcal{M}_2$ say, is the ratio of their evidences
\begin{equation} \label{Eqn:BF}
B_{12} = \frac{\pi(Y_{1:T} \vert \mathcal{M}_1)}{\pi(Y_{1:T} \vert \mathcal{M}_2)},
\end{equation}
\noindent where $\pi(Y_{1:T} \vert \mathcal{M}_m)$ is the evidence  for model $\mathcal{M}_m$.
The Bayes factor summarises the strength of evidence in the data in support of one model over another and is the ratio of the posterior to the prior odds in favour of $\mathcal{M}_1$ over $\mathcal{M}_2$.
If the prior probabilities for each model are equal then the Bayes factor is equivalent to the ratio of the posterior model probabilities.

Secondary aims of our analysis include parameter estimation and filtering, which in this context are often called calibration and climate reconstruction (or hindcasting). Let $\theta_m$ denote the parameter for model $\mathcal{M}_m$. 
Calibration is the process of finding the posterior distribution of the model parameters $\pi(\theta_m | y_{1:T}, \mathcal{M}_m)$, and filtering is finding the distributions of the state variables $\pi(X_{1:T} | Y_{1:T}, \theta_m, \mathcal{M}_m)$. These three problems are of different levels of difficulty. Filtering is the simplest, but by no means simple. It involves finding the posterior distribution of a high dimensional object $X_{1:T}$ and for non-linear or non-Gaussian models, direct calculation of the filtering distributions is impossible, and so we must instead rely upon approximations.
Calibration requires that we integrate out the dependence of $X_{1:T}$, 
\begin{equation}
\pi (\theta_m \vert Y_{1:T}, \mathcal{M}_m) = \int \pi(\theta_m, X_{1:T} \vert Y_{1:T}, \mathcal{M}_m) {\rm d}X_{1:T},
\end{equation}
and so is usually considerably more difficult than filtering. 
Finally, model selection requires the integration of the dependence on $\theta$, 
\begin{equation}
\pi (Y_{1:T} \vert \mathcal{M}_m) = \int \pi(\theta_m \vert \mathcal{M}_m) \pi(Y_{1:T} \vert \theta_m, \mathcal{M}_m) {\rm d}\theta,
\end{equation}
and is thus more difficult than calibration. 



The development of Monte Carlo methodology for solving these three problems for state space models reflects this hierarchy of difficulty. Particle filter methodology, first proposed in the 1990s \cite{Gordon1993}, is able to solve the general filtering problem adequately as long as the dimension of $X$ is not too large. Solving the calibration problem, however,  has  only begun to be satisfactorily answered more recently, with the development of pseudo-marginal methods such as particle-MCMC \cite{Andrieu2010}. Calculating the model evidence is still very much on open problem.

\rdw{We might just be inviting trouble by saying these this.}

Here, we demonstrate how the recently introduced SMC$^2$ algorithm \cite{Chopin2012} can be used to estimate model evidences. The technique is not perfect, as it is computationally costly, and results in BF estimates with large variance, but we can think of no other approach for solving this problem, and as we will demonstrate, often the strength of evidence in the data is sufficiently strong so that the estimated BFs are large enough for the estimation variance to be of no impediment to inference.

The approach relies upon the following identities. The evidence can be decomposed as
\begin{equation}\label{eqn:Ident1}
\pi(Y_{1:T}) =\pi(Y_1) \prod \pi(Y_t | Y_{1:t-1})
\end{equation}
where we have dropped the dependence on $\mathcal{M}_m$.
We can further write 
\begin{equation}\label{eqn:Ident2}
\pi(Y_t | Y_{1:t-1}) = \int \pi(Y_t | Y_{1:t-1}, \theta) \pi(\theta | Y_{1:t-1}) {\rm d} \theta.
\end{equation}
SMC$^2$ is then used to find unbiased estimates of $\pi(\theta | Y_{1:t-1})$ and $ \pi(Y_t | Y_{1:t-1}, \theta)$. Remarkably, pluggingg these estimates into Equations (\ref{eqn:Ident1}) and (\ref{eqn:Ident2}) then leads to unbiased estimates of the model evidence.



\rdw{ UPPER OR LOWER CASE Y?}


\subsection{Estimating model evidence using SMC$^2$}

Sequential Monte Carlo algorithms \cite{DelMoral2006} are population-based sampling methods aimed at obtaining a sample from some target distribution that is difficult to sample from directly.
A series of intermediary distributions $\{ \pi_t \}_{t=1}^T$ are chosen that `close-in' on the target distribution, $\pi_T$, from some easily sampled distribution $\pi_1$. SMC uses a weighted collection of particles to approximate each distribution, and sequentially updates the weights and the particles.
Usually the sequence of distributions is taken to be the sequence formed by adding the data a point at a time. e.g., $\pi(\theta |y_{1:T})$ or $\pi(x_{t}|y_{1:t})$.

One of the earliest and best known SMC algorithms \cite{Gordon1993} is designed  to sample from the sequence of filtering distributions $\pi_t = \pi(X_t \vert \theta, Y_{1:t})$. These algorithms are termed particle filters (PFs) and work as follows.
First, a sample of $N_x$ particles are sampled from the initial density $\pi (X_1 \vert \theta)$, and given importance weight $\pi (Y_1 \vert X_1, \theta)$.
These particles are then repeatedly resampled, propagated and weighted, such that for each successive iteration the particles are a weighted sample of the posterior $\pi(X_t \vert \theta, Y_{1:t})$.
The algorithm is as follows, where superscript $n$ indicates that the operation is performed for  $n = 1,...,N_x$.

\noindent \rule{\textwidth}{1pt}\\
\noindent {\bf Particle Filter}

\begin{itemize}
\item {\bf PF 1.} Sample state particles $X_1^n \sim q_1(\cdot \vert \theta, Y_1)$
\item {\bf PF 2.} Weight the state particles
\[ w_1^n (X_1^n) = \frac{\pi(X_1^n \vert \theta) \pi(Y_1 \vert X_1^n)}{q_1(X_1^n \vert \theta, Y_1)}, \hspace{1cm} W_1^{n} = \frac{w_1^n (X_1^n)}{\sum w_1^n (X_1^n)}.\]
\item {\bf PF 3.} For time index $t=2,...,T$
\begin{itemize}
\item {\bf PF 3.1.} Resample the ancestor particle index $\mathcal{A}_{t-1}^n \sim \mathcal{F}(W_{t-1}^n)$
\item {\bf PF 3.2.} Propagate the state particles $X_t^n \sim q_t(\cdot \vert X_{t-1}^{\mathcal{A}_{t-1}^n}, \theta, Y_t)$ and extend trajectory $X_{1:t}^n = \left(X_{1:t-1}^{\mathcal{A}_{t-1}^n}, X_t^n \right)$
\item {\bf PF 3.3.} Weight state particles
\[ w_t^n(X_{1:t}^n) = \frac{\pi(X_t^n \vert X_{t-1}^{\mathcal{A}_{t-1}^n}, \theta) \pi(Y_t \vert X_t^n)}{q_t(X_t^n \vert X_{t-1}^{\mathcal{A}_{t-1}^n}, \theta, Y_t)} , \hspace{1cm} W_t^n = \frac{w_t^n (X_{1:t}^n)}{\sum w_t^n (X_{1:t}^n)}. \]
\end{itemize}
\end{itemize}

\noindent \rule{\textwidth}{1pt}

\vspace{10pt}

\noindent Here, $\mathcal{F}(W_{t-1}^{1:N_x})$ denotes sampling an index from  $\{ 1,...,N_x\}$ according to weights $\{W_{t-1}^n\}_{n=1}^{N_x}$, and  $q_t$ denotes the proposal distribution at time $t$. Details of the resampling step $\mathcal{F}$ and the proposal distribution  $q_t$ are discussed in section \S.



An important aspect of the PF is that an unbiased estimate of $\pi (Y_t \vert Y_{1:t-1}, \theta)$ can be  obtained by averaging over the unnormalised weights in each iteration of the algorithm
\begin{equation}\label{eqn:Ident4}
\hat{\pi} (Y_t \vert Y_{1:t-1}, \theta) = \frac{1}{N_x} \sum_{n=1}^{N_x} w_t^n (X_{1:t}^n).
\end{equation}
and that an unbiased estimator of the marginal likelihood $\pi (Y_{1:t} \vert  \theta)$ can be obtained by plugging these estimates into the identity \cite{DelMoral2004}
\begin{equation}\label{eqn:Ident3}
\hat{\pi} (Y_{1:T} \vert \theta) = \hat{\pi}(Y_1) \prod_{t=2}^T \hat{\pi} (Y_t \vert Y_{1:t-1}, \theta).
\end{equation}
\cite{Andrieu2009} showed that using these unbiased estimates of the likelihood in other Monte Carlo algorithms can lead to valid Monte Carlo algorithms (termed pseudo-marginal algorithms) for performing parameter estimation. For example, PMCMC \cite{Andrieu2010} uses the PF within an MCMC algorithm, and SMC$^2$ \cite{Chopin2012} uses a PF embedded within an SMC algorithm, both with the aim of finding $\pi(\theta | Y_{1:T})$.


The SMC$^2$ algorithm \cite{Chopin2012} embeds the particle filter within an SMC algorithm targetting the sequence of posteriors
\begin{equation*}
\pi_0 = \pi(\theta), \hspace{1cm} \pi_t = \pi(\theta, X_{1:t} \vert Y_{1:t}),
\end{equation*}
for $t=1, \ldots, T$. 
This is achieved by sampling $N_\theta$ parameter particles, $\{\theta^j\}_{j=1}^{N_\theta}$ from the prior. To each $\theta^j$, we attach a PF of  $N_x$ particles, i.e., at iteration $t$ the PF $\{X_{1:t}^{n,j}, W_t^{n,j}\}_{n=1}^{N_x}$ is associated with $\theta^j$, which provides an unbiased estimate of the marginal likelihood $\pi(y_{1:t} |\theta^j)$ via a version of Equation (\ref{eqn:Ident3}). To assimilate the next observation $y_{t+1}$, we first extend the PF for the X-states to $\{X_{1:t+1}^{n,j}, W_{t+1}^{n,j}\}_{n=1}^{N_x}$, and then estimate $\pi(Y_{1:t+1} | \theta^j)$ etc. 
Degeneracy occurs when the weighted particle approximation is dominated by just  a few particles (i.e. a few have comparatively large weights).
It can be monitored by calculating the effective sample size (ESS)\footnote{ESS$ = \left( \sum  \left( \Omega^m \right)^2 \right)^{-1}$ where $\Omega^m$ are the normalised weights.}.
When the ESS falls below some threshold (usually $N_\theta / 2$) the particles are resampled to discard low-weight particles.
However, resampling alone would lead to too few unique particles in the parameter space.
Particle diversity is improved by running a PMCMC algorithm that leaves $\pi (\theta, X_{1:t} \vert Y_{1:t})$ invariant, specifically the PMMH algorithm \cite{Andrieu2010}.
The algorithm is given below, but the reader is referred to the original paper for the theoretical justification \cite{Chopin2012}.
Superscript $j$ indicates that the operation is performed for all $j = 1,...,N_{\theta}$.

\noindent \rule{\textwidth}{1pt}\\
\noindent {\bf SMC$^2$}

\begin{itemize}
\item {\bf SMC$^2$ 1.} Sample parameter particles $\theta^j \sim \pi(\theta)$

\item {\bf SMC$^2$ 2.} Set importance weights $ \Omega^j = \frac{1}{N_\theta}$

\item {\bf SMC$^2$ 3.} For $t=1,...,T$

\begin{itemize}

\item {\bf SMC$^2$ 3.1.} For each parameter particle $\theta^j$, extend the associated PF  $\{X_{1:t-1}^{n,j}, W_{t-1}^{n,j}\}_{n=1}^{N_x}$ to  $\{X_{1:t}^{n,j}, W_t^{n,j}\}_{n=1}^{N_x}$ by performing iteration $t$ of the PF.

\item {\bf SMC$^2$ 3.2.} Calculate $\hat{\pi} (Y_t \vert Y_{1:t-1}, \theta^j)$ using Equation (\ref{eqn:Ident4}) and calculate the weighted average over the parameter particles to obtain $$\hat{\pi}(Y_t \vert Y_{t-1}) = \sum_{j=1}^{N_\theta} \Omega^j \hat{\pi} (Y_t \vert Y_{1:t-1}, \theta^j)$$

\item {\bf SMC$^2$ 3.3.} Update the importance weights
\[ \omega^j = \omega^j \hat{\pi} (Y_t \vert Y_{1:t-1}, \theta^j), \hspace{1cm} \Omega^j = \frac{\omega^j}{\sum \omega^j} \]

\item {\bf SMC$^2$ 3.4.} If the ESS falls below some threshold,  resample. For $j=1, \ldots, N_\theta$:

\begin{itemize}

\item {\bf SMC$^2$ 3.4.1.} Sample an index
 J from $\{1, \ldots, N_\theta\}$ %and corresponding PF $\left( \theta^j, \{X_{1:t}^{n,j} ,W_t^n\}_{n=1}^{N_x} \right)$ 
according to weights $\Omega^j$.

\item {\bf SMC$^2$ 3.4.2.} Sample $\left( \theta, \{X_{1:t}^n, W_t^n\}_{n=1}^{N_x} \right)^{*} \sim K \left(\cdot \vert \left( \theta^J, \{X_{1:t}^{n,J} ,W_t^{n,J}\}_{n=1}^{N_x} \right)\right)$ where $K$ is a PMCMC kernel that leaves $\pi (\theta, X_{1:t} \vert Y_{1:t})$ invariant.

\item {\bf SMC$^2$ 3.4.3.} Set $\left( \theta^j, X_{1:t}^{1:n,j} \right) \leftarrow \left( \theta, X_{1:t} \right)^{*}$



\end{itemize}
Set importance weights
$\Omega^j = \frac{1}{N_\theta}$
\end{itemize}

\end{itemize}

\noindent \rule{\textwidth}{1pt}

\vspace{10pt}
  
 SMC$^2$ naturally provides an estimate of the model evidence.
The model evidence can be decomposed according to Equation (\ref{eqn:Ident1}), and in each iteration of SMC$^2$, the term 
\[ \hat{\pi}(Y_t \vert Y_{t-1}) = \sum \Omega^j \hat{\pi} (Y_t \vert Y_{1:t-1}, \theta^j) \]
\noindent calculated in step {\bf SMC$^2$ 3.2}, is an unbiased estimate of $\pi(Y_t \vert Y_{t-1})$.
An estimate of the model evidence is provided by the product of these terms.


\subsection{Guided proposals}

A further difficulty arises because for the models of interest, the transition densities 
$\pi(X_t \vert X_{t-1}, \theta)$ are not available in closed form, 
and so we need to choose the particle proposals $q_t$ so that this term cancels. 
This can achieved by setting $q_t = \pi(X_t \vert X_{t-1}, \theta)$ for $t > 1$, so that proposals are just simulations from the model.
However, this choice will typically lead to particle degeneracy if too many of the proposals end up being far from the observations, so that the small number of proposals in the region of the observation gain nearly all of the weight.
Resampling the state particles can improve the approximation in later iterations as only important particles are propagated forward. The choice of $\mathcal{F}$ ...\rdw{Jake - say something here about the sampling mechanism}

Possible resampling strategies are discussed in \cite{Liu1998}.
\mcr{I believe \emph{can} is here crucial. Isn't the essence of the Golighty-Wilkinson proposal to propose an alternative to this proposal,
but yet keeping a ratio $q \over \pi$ which is analytical ? Should this be mentioned at this stage?}


Where possible, including information from the next observation $y_t$ in the proposals at time $t$ should lead to more equal weights.
For the models considered in this article, it is possible to condition proposals on the next observation under the Euler-Maruyama approximation, which should move more particles to regions of high posterior probability.
Starting with the Euler-Maruyama approximation
\[ X_{t+\Delta t} \sim \mathcal{N} (X_t + \mu \Delta t, \Sigma_x \Delta t), \]
we want to design a proposal that moves the observable state closer an observation at time $T$, where $T-t$ is usually too large for a single Euler step.

\rdw{Jake: We need to sort out notation here. The $t$ in  $X_t$ is a counting index, rather than a time index, and so $X_{t+\Delta t}$ doesn't make sense. Perhaps we could use $X(\tau)$?}

\rdw{I find the rest of this section from here nearly completely impenetrable, even though we've talked through it several times. Could you have another go, and see if its readability can be improved.}

Firstly, we can consider adding a small perturbation to the mean of the proposal of the form 
\[J S^{-1} (Y_T - (D + S(X_t + \mu (T-t)))), \]
\noindent where a single Euler step is used to predict the value of $X_T$, which is then compared to the the observation (residual nudging reference?).
$J$ determines how strongly the observation influences the proposal.
\mcr{is it useful here to write the analytical form of $\pi_t \over q$ or is it considered obvious enough for the audience?}
The optimal choice will depend on the relative variance of the model, and the observation.
For the case $\Delta t = T-t$ it is desired that $J \rightarrow 1$ as $\Sigma_y \diagup S^2 \Sigma_x (T-t) \rightarrow 0$, and $J \rightarrow 0$ as $S^2 \Sigma_x (T-t) \diagup \Sigma_y \rightarrow 0$.
This suggests $J= S^2 \Sigma_x (T-t) \diagup \left(S^2 \Sigma (T-t) + \Sigma_y \right)$, a form shared with the Kalman gain matrix.
When using smaller integration time steps $J$ is multiplied by $\Delta t / (T-t)$ to give the proportion of the perturbation that occurs over the smaller time step.

A similar proposal has been more formally derived by using Brownian bridges conditioned on observations \cite{Golightly2008}, which also reduces the variance of the proposals as the observation is neared.
This is expected to be beneficial for informative observations as ensuring the state of the system is near an observation before reaching it prevents rapid state changes (which will have low likelihood).
The specific variance reduction (when taking the scaling term in to account) is given by:
\[ \left(\frac{S^2 \Sigma_x (T-t) - S^2 \Sigma_x \Delta t + \Sigma_y}{S^2 \Sigma_x (T-t) + \Sigma_y} \right) S^2 \Sigma_x \Delta t, \]
\noindent which scales down the variance based on the model variance, the observation variance, the time until the observation, and the integration time step.
\mcr{I am unsure but I believe the $S^2$ before $\Sigma_x$ is superfluous.}
The ratio can be considered as the variance remaining after the integration step has been performed relative to the total variance.
This ratio is close to 1 for $\Delta t \ll (T-t)$, and for $S^2 \Sigma_x \Delta t \ll \Sigma_y$.
Whereas in the case $\Delta t = \Delta T$, and $\Sigma_y \ll S^2 \Sigma_x \Delta t$ the proposal variance is approximately the observation variance.


Combining these changes gives a proposal of the form
\begin{multline}
X_{t+\Delta t} \sim \mathcal{N} (X_t + \mu \Delta t + \frac{S^2 \Sigma_x \Delta t}{S^2 \Sigma_x (T-t) + \Sigma_y} S^{-1} (Y_T - (D + S(X_t + \mu (T-t)))) ,\\ \left(\frac{S^2 \Sigma_x (T-t) - S^2 \Sigma_x \Delta t + \Sigma_y}{S^2 \Sigma_x (T-t) + \Sigma_y} \right) S^2 \Sigma_x \Delta t),
\end{multline}
\mcr{I am unsure but I believe the $S^2$ before $\Sigma_x$ is superfluous.}
\noindent such that for uninformative observations the proposal is approximately the standard Euler-Maruyama approximation, and for informative observations the value of $X_T$ is drawn from $\mathcal{N}((Y_T-D) \diagup S, \Sigma_y \diagup S^2)$.
In other words the proposal will be centered on the observation with variance equal to the observation error.



\subsection{Further details}


\noindent The tuning parameters are the number of particles $N_\theta$ and $N_x$, and the proposal distributions for the PMCMC steps in {\bf SMC$^2$ 3.4.2.} Typically $N_\theta$ will be decided by the available computational resources.
A low $N_x$ can be used for early iterations, but must be increased for larger times.
An insufficient number of state particles will have a negative impact on the PMCMC acceptance rate.
Automatic calibration of $N_x$ is discussed in \cite{Chopin2012}, where it is suggested that $N_x$ is doubled whenever the acceptance rate of the PMCMC step becomes too small.
The fact that we have a collection of particles in each iteration allows automated calibration of the PMCMC proposals; for example by using the sample mean and variance to design a sensible random-walk proposal, or independent Gaussian proposals.



For complex models, filtering presents significant challenges, and usually approximate techniques such as 4d-Var, and Kalman filter type algorithms are used.  Can we substitute?


GPU computation and timings needed.

\mcr{I believe we need to give a bit more detail about the 3.4.1 resampling step, I mean, the details (binomial vs residual)}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
% Methodology
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\clearpage
\section{Results}
\label{Sec:Results}




\subsection{Simulation study}
In order to gain confidence in the ability of our SMC$^2$ algorithm for both model selection and calibration, we begin with a simulation study.
We simulate a single random trajectory from a given model and parameter setting and draw observations from the observation process. We then show that the posterior distributions recover the true value of the parameters (Figure \ref{Fig:PosteriorSS}), and that the Bayes factors correctly identify the true generative model (Table \ref{Tab:EvidenceSS}).

We present results from analysing two simulated datasets: one in which data are generated from an unforced version of SM91, and one in which a forced version of SM91 is used. 
We refer to these datasets as SM91-u and SM91-f respectively. The parameters used are given in Table \ref{Tab:EvidenceSS} and are comparable to those estimated from real data. Crucially, realistic values of the measurement error variance are used. 
Observations are taken every $3$kyr over the past $780$kyr giving 261 observations in each dataset, which  is comparable to a  low resolution sediment core.
The model evidence and posteriors are then calculated for  each of five models. We use  forced and unforced versions of SM91 and T06, as well as the forced model PP12. We do not consider an unforced PP12 model as the deglatiation-glaciation transition depends only on the astronomical forcing, whereas SM91 and T06 both oscillate in the absence of any external forcing. The models contain between 10 and 16 parameters. We then test the ability of  our inference algorithms to 1) discriminate between the five models by  estimating  the Bayes factors; 2) recover the parameters used to generate the data; and 3) reconstruct the underlying climate trajectories $x_{1:T}$.
The priors used for each model are given in Table~\ref{Tab:Priors}.


\begin{center}
\begin{LARGE}
TABLE \ref{Tab:Priors} ABOUT HERE
\end{LARGE}
\end{center}



The estimated log Bayes factors (log BF) 
 are given in Table~\ref{Tab:EvidenceSS}. 
The  Bayes factor of two models is the ratio of the model evidences. However, the logarithm of the Bayes factor provides a more natural scale for interpretation, with the log BF calculated as the difference between two log evidences, and this is what is reported in Table~\ref{Tab:EvidenceSS}.
A common interpretation suggests that a log BF of 3 is strong evidence in favour  of one model over another, and that a log BF of 5 is a very strong indication that one model is superior to another \cite{Kass1995}. Conversely, a negative score indicates the same strength of evidence but in the other direction (for the other model).

For both simulated datasets, we find a strong preference for the correct model.
When applied to SM91-f, the correct model (the forced SM91 model) is overwhelmingly favoured. The log BF to the next most supported model (the forced T06 model) is estimated to be 24.7,  indicating decisive evidence in favour of the true model.
It is interesting to note that if we remove the forced SM91 model from the analysis, we find decisive evidence in favour of the forced T06 model over any of the other unforced models (a log BF of at least 27.7), showing that the astronomical forcing has explanatory power even in the wrong model. This is not particularly surprising, because in both models the astronomical forcing acts as a synchronisation agent, controlling the timing of terminations, and has a strong effect on the likelihood. This is reassuring. It means that palaeoclimate scientists can implicitly rely upon this effect when arguing for the importance of the astronomical forcing, as it allows us to infer its importance even when using an incorrect simulator (for we surely are). \rdw{Does this make sense -  it may be a little strong.}


When applied to SM91-u the log BF again correctly identifies the correct generative model, although the support for the unforced and forced SM91 models is now much closer (with a log BF of 2.9 in favour of the unforced model). In cases where the forcing does not add any explanatory power this is an expected result, as the unforced version of SM91 is nested within the forced version of SM91, and is recovered by setting $\gamma_P = \gamma_C = \gamma_E = 0$. This effect is also noticeable when comparing the forced and unforced T06 models, with the unforced version being preferred with a log BF of 3.5. 

These experiments clearly show  that there is  sufficient information in the data to easily detect the correct parametric form of the simulator in each case. Care needs to be taken when using Monte Carlo estimates of the model evidences, as the Monte Carlo error can be considerable.
Experimentation suggests that the model evidence estimates have a variance of approximately an order of magnitude, and hence the log Bayes factors should be viewed as having uncertainty of approximately plus or minus 6 on the log scale.
We thus suggest that we can only be confident that there is strong evidence for one model over another if the estimated log BF is at least 10. Note that our conclusions from the simulation study are mostly unaffected by this noise, aside from further confirming that the difference between the forced and unforced version of the same parametric model is small. 
The magnitude of the estimation error can be decreased by using more particles in the SMC$^2$ algorithm, but this will require very long computational runs. uUsing $N_x=N_\theta=1000$.... JAKE CAN YOU SORT - takes ??? hours on a GPU..... and the cost increases as $O(N_x^2)$????. Nested sampling \cite{Skilling2006} is an alternative approach to estimating BFs that allows for easier estimation of sampling uncertainty. However, implementing nested sampling for intractable models with a large number of missing values (as in this case, where the trajectories are `missing data') has not yet proven possible, but if it can be made to work, would be worth pursing.
 
\mcr{although this discussion avoids the problem of the robustness vs the choice of priors, especially if the latter are vague}



\begin{center}
\begin{LARGE}
TABLE \ref{Tab:EvidenceSS} ABOUT HERE
\end{LARGE}
\end{center}



The marginal posterior distributions for the parameters for the forced SM91 model applied to the SM91-f dataset are shown in Figure~\ref{Fig:PosteriorSS}.
We are able to recover the parameters used to generate the data, with the true values lying in regions of high posterior probability.
The posteriors for $q$ and $\sigma_3$ do not deviate much from the prior, suggesting that a wide range of values explain the data equally well.
Further simulation studies and details are available in \cite{Carson2014}.


\begin{center}
\begin{LARGE}
Figure \ref{Fig:PosteriorSS} about here.
\end{LARGE}
\end{center}




\rdw{Can you add a plot showing the three SM91 trajectories, with the MC confidence interval, and the data from $y_1$. I think this would help illustrate, even if it is likely to end up in supplementary material.}

\subsection{ODP677}
\rdw{We need more detail on the data here.}

We now analyse data from the ocean drilling programme (ODP). We focus here on ODP677, sampled in the western equatorial Pacific  
\cite{SHACKLETON90aa}. The foraminifera  here are of the benthic form, living in the deep ocean and therefore thought to be better representative of continental ice volume variations (see, though \cite{Elderfield12aa}). Analysis of other datasets can be found in \cite{Carson2014}. When an ocean core is first extracted and analysed, the measurements are a sequence of proxy measurements ($\delta^{18}O$) corresponding to different depths in the core. The core is then dated through the use of an age-model. When different age models are used, they can give slightly different chronologies for the same core. ODP677 is interesting in this regard, as it has been dated by two different groups. In \cite{Huybers2007}, a depth-derived age model is used.  `Age-control points' are identified in the core (such as glacial terminations, magnetic reversals, etc), and then ages for all the measurements are inferred from these control points, while accounting for compression   in an involved heuristic process. We will refer to the data from this study as ODP677-u, where the `u' denotes {\it unforced}. In  \cite{Lisiecki2005}, the core is dated using an orbitally-tuned age model. Specifically, ice ages are aligned with the predictions of the Imbrie and Imbrie (1980) model (linear relaxation but with different relaxation times for glaciation and deglaciation) 
\cite{imbrie80} forced  by summer solstice insolation at 60 \degree N).

The estimated log Bayes factors for each model are given in Table~\ref{Tab:EvidenceODP}. 
For ODP677-u, the unforced T06 model is best supported, but the estimated BF for the unforced T06 model compared to the unforced SM91 model is within our Monte Carlo bounds, and so it is not possible to confidently assert that T06 is superior to SM91 for explaining these data. There is reasonable to strong evidence (given our Monte Carlo uncertainty) that the unforced models are preferred to the forced model, i.e., there is reasonable evidence that we do not need an astronomically forced model to explain the data. This resembles the results from SM91-u, where the forced models are being penalised for containing extra parameters with little explanatory power. Note that the two unforced models are both decisively preferred compared to PP12.


\begin{center}
\begin{LARGE}
TABLE \ref{Tab:EvidenceODP} ABOUT HERE
\end{LARGE}
\end{center}


When we analyse ODP677-f, the astronomically tuned data, the results are the complete reverse. We now find that the PP12 model is strongly indicated by the data, and that the three forced models are all decisively preferred to the two unforced models, i.e., we find overwhelming evidence using these data that astronomical forcing is necessary to explain the data!
The orbital tuning of ODP677-f is the most likely explanation for this.
In SM91 and T06 the astronomical forcing acts similarly as a pacemaker, controlling the timing of glacial inceptions and terminations. 
While in PP12 the astronomical forcing dictates the transition from the glaciated state to the deglaciated state.
As such, we might expect the output of PP12 to be more strongly correlated to the astronomical forcing in a similar fashion to ODP677-f.
Forced SM91 and forced T06 are both more supported than the unforced versions, with strong Bayes factors.
Again it is difficult to determine if T06 is more supported by the data than SM91.


This result is our second key finding. Namely, that inference about the best model is strongly affected by the age-model used to date the data. It is vital that modelling assumptions in the dating methods should be understood when performing inference on palaeoclimate data. We suggest that this demonstrates that the approach of first dating the data, and then carrying out down-stream analyses given this dating, ignoring the uncertainty, is at best harmful, and at worst, completely undermines any subsequent inference about the dynamic mechanisms at play.


\begin{center}
\begin{LARGE}
Figure \ref{Fig:PosteriorODP} about here.
\end{LARGE}
\end{center}

The marginal posterior distributions of the parameters in the SM91 model when fit to the ODP677-f data are shown in Figure~\ref{Fig:PosteriorODP}.
The astronomical forcing scaling parameters $\gamma_P$ and $\gamma_E$ have very small posterior probabilities at 0, suggesting that both precession and obliquity are informative about ODP677-f.
The scaling parameter for obliquity is typically larger than that for precession.
On the other hand for the coprecession parameter $\gamma_C$, 0 is in a region of very high posterior probability, indicating that a model selection experiment might support a forced model without coprecession.
This is true of the posterior values from any of the forced models.
The stochastic scaling parameters are larger than in simulation study, which is expected when data has not been generated from the model.

Finally, the density of the ratios $\frac{\gamma_P}{\gamma_E}$ and $\frac{\gamma_C}{\gamma_P}$ are shown in Figure~\ref{Fig:AFRatio}.
While the individual parameters are not directly comparable due to each model having different spatio-temporal scales, the ratio between the astronomical scaling terms gives the shape of the forcing function, and is comparable.
The forcing function in PP12 is ommitted due to the fact that the forcing is truncated, making the parameters incomparable.
While there is a slight difference, the posteriors are similar enough to suggest that each model is synchronising to the same forcing, with the obliquity scaling term being dominant.



\begin{center}
\begin{LARGE}
Figure \ref{Fig:AFRatio} about here.
\end{LARGE}
\end{center}



\section{Alternative approaches}
\label{Sec:Alt}

\rdw{We can probably ditch this section, or include a little at the end of the methodology section.
}
Decide what else to include, i.e.

\begin{itemize}
\item Kalman filter works in linear Gaussian case, and there exist a number of extensions that could be used to approximate the likelihood for nonlinear models.
Less computational cost than SMC$^2$, but we no longer have an `exact approximation'.
\item PMCMC could be used with reversible-jump steps.
What are the pros/cons compared to SMC$^2$.
\item ABC can be used. \mcr{Is that true for model evidence as well?}
In particular Richard has some comments on using summary statistics.
\item Information criterion approaches?
\end{itemize}

What's missing?
UKF
ABC comparison
Details of statistical improvements - SMC$^2$ for model selection
G and W updates.


\section{Conclusions}
\label{Sec:Conclusion}

We have two key conclusions.
The first is that Monte Carlo technology and computer power are now both sufficiently advanced, that with work, it is possible to fully solve the Bayesian model selection problem for a wide class of phenomenological models of the glacial-interglacial cycle. It came as a surprise to us, that even relatively short time-series of observations contain sufficient information to discriminate between many of the models. A priori, we had expected to find that there was simply insufficient information in the data, given the level of noise, to solve simultaneously the filtering and the model calibration problems, and then still distinguish between the models. That we are able to do this, contrasts strongly with the  viewpoint 
set out in \cite{Roe1999}:



\begin{quote}
Most simple models of the [...] glacial cycles have at least four degrees of freedom [parameters], and some have as many as twelve. Unsurprisingly [...this is] insufficient to distinguish between the skill of the various models
\end{quote}

\noindent In 1999 this viewpoint may have been true. We lacked both the computer power and the algorithmic knowledge to do Bayesian inference for the  parameters, never mind  estimating the Bayes factors. However, recently developments in Monte Carlo methodology, and the massive increase in computing power (including the utilisation of GPUs), means that the calculations are now possible. Using only 261 observations, we are able to learn up to 16 parameters,  state trajectories  containing $261\times 3$ values, and  calculate the marginal evidence. Moreover, these evidences are sufficiently different (and able to be estimated with sufficient accuracy) that we can confidently discriminate the ability of the models to explain the data.

\rdw{We don't want to be too critical of Roe and Allen, but we do want to stress why this work is cool!}

Our second conclusion concerns the need to avoid theory laden data. The results from analysing the  ODP677 data, show that the age model used to date the core become critical when the data are subsequently used to make scientific judgements. One age model gives overwhelming evidence that the astronomical forcing is vital for explaining the data, while another age model suggests the opposite. This suggests that analysing the data in stages, cutting feedbacks between uncertainties, is not sensible. While this observation is not new, we believe it is the first time the effect of the age model on subsequent analyses has been so clearly demonstrated.
Instead of first dating the core, and then using those dates (with or without uncertainties), we instead need to jointly estimate the age model at the same time as testing further hypotheses, accounting for all the joint uncertainties. 


\mcr{I believe one outstanding problem when we arrive to this conclusio is that the palaeclimatic conclusions all sound a bit naive. Remember that the SM91 model is a bit ancient, and that the T06 model rests an a controversial mechanism, and, again, in both cases, we are more discriminating the dynamics than the actual mechanisms that are featured by these models. With a benthic foram core, it seems indeed a bit overstretch to claim discerning the difference between a g/i mechanism resting on biogeochemical instability, and one resting on a sea-ice switch mechanism. We have to be careful not to be interpreted in this way. One necessary (and not sufficient) condition for appreciating the role of biogeochemistry or sea-ice (if we want to speak of these two models in particular) is to actually have data about these physical entities. }

\rdw{Michel, does the new results section and emphasis answer these concerns}

\mcr{
On the other hand, looking at the amount of code, notes written etc. that Jake and other of us have delivered in the last four years, we must have the material to say a bit more about our experience in model selection. E.g.: how many particles do we need? What is the rate of convergence? What is the improvement provided by the Golighty-Wilkinson algorithm : was it necessary to use this proposal? How did Jake chose the MH proposal when resampling particles? etc. All these elements are essential because if we admit that this was a ``simple" problem using after all oversimplified models, the merit of our experience is that it allows us to envision how this work can be extended to more data (mean : CO2, ice volume, methane, \ldots) and more physically explicit models. A few comments are inlined, but really we need to give this more thought. }

\rdw{I'll think about what we should add to Section 4}

%
%We have presented a principled inference approach for assimilating palaeclimate observations in to phenomenological models of the cliamte.
%We have shown how Bayesian model selection can be used to study a variety of problems in paleaoclimatology. 
%\mcr{yeeano :  we focused on a quite specific problem to be honest}
%The results are very much age-model dependent, with forced models being favoured when the data has been astronomically tuned.
%This is not a surprising find, but shows that caution is necessary when performing inference on palaeoclimate data \mcr{sure,\dots but that we new already}
%Choosing between phenomenological models is more challenging, supporting the notion that any sufficiently non-linear model can resemble the glacial-interglacial cycle over the past 800 kyr when synchronised with the astronomical forcing \cite{Cane2006,Tziperman2006}.
%However, it is worth noting that the favoured phenomenological model was also age-model dependent.
%We have also shown how the same approach can calibrate phenomenogical models of the climate, which is a difficult problem when stochastic perturbations are included.

The experiments included in this paper can be extended in several ways.
Firstly, we considered only a handful of models, and both the number and complexity of models can be increased. 
With the approach described here, extra models can be included by running the SMC$^2$ algorithm for each model.
This has the benefit that the entire experiment does not need to be redesigned/repeated for different combinations of models.
Different astronomical forcing set-ups can also be considered.
For example, the astronomical forcing terms are often tested independently.
This can easily be achieved by setting undesired astronomical scaling terms to 0 in our forced models.
Making the forcing term state dependent, such that an increase in sea-ice increases albedo , which in turn alters the influence of variation in insolation is also a possibility. \mcr{it is not so much a problem of sea-ice but, for example, the ablation area grows non-linearly with insolation; there are references for this but we can see this later.}
Finally, we do not need to limit ourselves to a single dataset.
The observation model can be extended to compare the state of the system to multiple cores.
Likewise, multivariate observations could be used; SM91 models both ice-volume and CO$_2$ concentration, and records exist for both of these quantities.


Overall, we hope that this work acts as a proof of concept. Careful statistical analysis combining data and models can lead to insights in palaeoclimate science.

\rdw{Jake: the references need sorting. Initials are being lost in names, as you need to separate them with a space, e.g., R. D. Wilkinson, not R.D. Wilkinson}

\clearpage

\bibliographystyle{ieeetr}	% (uses file "plain.bst")
\addcontentsline{toc}{chapter}{References}
\bibliography{FullReferences}



\clearpage
\begin{table}
\begin{center}
\begin{tabular}{lll}
\toprule
SM91 & T06 &PP12 \\
\midrule
$\gamma_P \sim \operatorname{Exp}(1 \diagup 0.3)$ & $\gamma_P\sim \operatorname{Exp}(1 \diagup 0.6)$ & $\gamma_P\sim \operatorname{Exp}(1 \diagup 1.5)$ \\
$\gamma_C\sim \operatorname{Exp}(1 \diagup 0.3)$ & $\gamma_C\sim \operatorname{Exp}(1 \diagup 0.6)$ & $\gamma_C\sim \operatorname{Exp}(1 \diagup 1.5)$ \\
$\gamma_E\sim \operatorname{Exp}(1 \diagup 0.3)$ & $\gamma_E\sim \operatorname{Exp}(1 \diagup 0.6)$ & $\gamma_E\sim \operatorname{Exp}(1 \diagup 1.5)$ \\
&  & \\
$p\sim \Gamma(2,1.2)$ & $p_0\sim \operatorname{Exp}(1 \diagup 0.3)$ & $a\sim \Gamma(8,0.1)$\\
$q\sim \Gamma(7,3)$ & $K\sim \operatorname{Exp}(1 \diagup 0.1)$ & $a_d\sim \operatorname{Exp}(1)$\\
$r\sim \Gamma(2,1.2)$ & $s\sim \operatorname{Exp}(1 \diagup 0.3)$ & $a_g\sim \operatorname{Exp}(1)$\\
$s\sim \Gamma(2,1.2)$ & $\alpha\sim \operatorname{Beta}(40,30)$ & $\kappa_P\sim \operatorname{Exp}(1 \diagup 20)$ \\ 
$v\sim \operatorname{Exp}(1/0.3)$ & $x_l\sim \operatorname{Exp}(1 \diagup 3)$ & $\kappa_C\sim \operatorname{Exp}(1 \diagup 20)$ \\
$\sigma_1\sim \operatorname{Exp}(1 \diagup 0.3)$ & $x_u\sim \Gamma(90,0.5)$ & $\kappa_E\sim \operatorname{Exp}(1 \diagup 20)$ \\
$\sigma_2\sim \operatorname{Exp}(1 \diagup 0.3)$ & $\sigma_1\sim \operatorname{Exp}(1 \diagup 2)$ & $\tau\sim \operatorname{Exp}(1 \diagup 10)$ \\
$\sigma_3\sim \operatorname{Exp}(1 \diagup 0.3)$ & & $v_0 \sim \Gamma(220,0.5)$ \\
& &  $v_1\sim \operatorname{Exp}(1 \diagup 5)$\\
& &  $\sigma_1\sim \operatorname{Exp}(1 \diagup 5)$ \\
&   & \\
$D\sim \operatorname{U}(2.5,4.5)$ & $D\sim \operatorname{U}(2.5,4.5)$ & $D\sim \operatorname{U}(2.5,4.5)$ \\
$S\sim \operatorname{U}(0.25,1.25)$ & $S\sim \operatorname{U}(0.02,0.05)$ & $S\sim \operatorname{U}(0.01,0.03)$ \\
$\sigma_y\sim \operatorname{Exp}(1 \diagup 0.1)$ & $\sigma_y\sim \operatorname{Exp}(1 \diagup 0.1)$ & $\sigma_y\sim \operatorname{Exp}(1 \diagup 0.1)$ \\
\bottomrule
\end{tabular}
\label{Tab:Priors}
\caption{Prior distributions used for each model in both the simulation study and the analysis of ODP677.
Sections indicate parameters used to scale the astronomical forcing (absent in unforced models), parameters of the phenomenological model, and observation model respectively.
JAKE/MICHEL - can we say something about how these priors were chosen.
}
\end{center}
\end{table}


\clearpage


\begin{table}
\begin{center}
\begin{tabular}{ l l  c c }
\toprule
\multicolumn{2}{c}{Model} & \multicolumn{2}{c}{Dataset} \\
%\cline{3-6}
& & SM91-u & SM91-f\\
\midrule
SM91 & Forced & $-2.9$ & $0$\\
 & Unforced & $0$ & $-52.4$ \\
T06 & Forced & $-21.8$ & $-24.7$   \\
 & Unforced & $-18.3$ & $-61.4$ \\ 
PP12 & Forced & $-49.6$ & $-52.5$ \\
\bottomrule
\end{tabular}
\caption{Log Bayes factors for comparing five different models on the two simulated datasets. In each column, the log BF is with respect to the true generative model, so that positive values indicate support for that model over the true model, and negative values indicate support for the true model. SM91-u is data generated from an unforced version of SM91, whereas SM91-f is generated from an astronomically forced version of SM91.
Values of the log evidence can be reconstructed from noting that $\log Z=69.2$ for the unforced version of SM91 on the SM91-u dataset, and that $\log Z = 94.7$ for the forced SM91 model on the SM91-f dataset. The parameter values used to generate SM91-f are: $p=0.8$, $q=1.6$, $r=0.6$, $s=1.4$, $v=0.3$, $\sigma_1=0.2$, $\sigma_2=0.3$, $\sigma_3=0.3$, $\gamma_P=0.3$, $\gamma_C=0.1$, $\gamma_E=0.4$, $D=3.8$, $S=0.8$, $\sigma_y=0.1$.
For SM91-u we set $\gamma_P = \gamma_C = \gamma_E = 0$.
QUESTION: I've played around with various ways of presenting this information, including the original evidence, the log evidence, and the log BF compared to the worst model. I think this is the clearest - do you agree?
WARNING: rounding errors here as I've taken Jake's Z value to two dp and logged it.
}
\label{Tab:EvidenceSS}
\end{center}
\end{table}



\clearpage


\begin{table}
\begin{center}
\begin{tabular}{ l l  c c  }
\toprule
\multicolumn{2}{c}{Model} & \multicolumn{2}{c}{Dataset} \\
%\cline{3-6}
& & ODP677-u & ODP677-f\\
\midrule
SM91 & Forced &  $-8.4$ & $-14.3$ \\
 & Unforced &  $-3.9$ & $-37.0$ \\
T06 & Forced & $-6.2$ & $ -10.6$  \\
 & Unforced &  $0$ & $-29.4$  \\ 
PP12 & Forced & $-13.9$ & $0$  \\
\bottomrule
\end{tabular}
\caption{
The estimated log BFs for the five different models. The Bayes factors are given in comparison to the best model for each dataset (which thus has a log BF of zero).
The ODP677 dataset is analysed twice. ODP677-u refers to a dating model derived by \cite{Huybers2007} using a depth derived model, whereas ODP677-f is an astronomically tuned dating model described in \cite{Lisiecki2005}.
Values of the log evidence can be reconstructed using the estimates  $\log Z=65.0$ for the unforced version of T06 on the ODP677-u dataset, and that $\log Z = 78.9$ for the PP12 model on the ODP677-f dataset. The prior distributions used are given in Table \ref{Tab:Priors}.
WARNING: rounding errors here as I've taken Jake's Z value to two dp and logged it. Values of the log evidence
}
\label{Tab:EvidenceODP}
\end{center}
\end{table}


%
%\begin{table}[t]
%\begin{center}
%\begin{tabular}{ l l  c c }
%\toprule
%\multicolumn{2}{c}{Model} & \multicolumn{2}{c}{Dataset} \\
%%\cline{3-6}
%& & SM91-u & SM91-f\\
%\midrule
%SM91 & Forced & $46.7$ & $61.4$\\
% & Unforced & $49.6$ & $9.0$ \\
%T06 & Forced & $27.8$ & $36.7$   \\
% & Unforced & $31.3$ & $0$ \\ 
%PP12 & Forced & $0$ & $8.9$ \\
%\bottomrule
%\end{tabular}
%\caption{WARNING: rounding errors here as I've taken Jake's Z value to two dp and logged it.
%The log model evidences  for each model and dataset. Only relative differences matter, and so we have subtracted the minimum value found from each column so that the worst supported model is given a value of 0.
%The four datasets are i) SM91-u: data simulated from an unforced version of SM91 ii) SM91-f: data simulated from a forced version of SM91 iii) ODP677-u: real data from the ocean drilling programme dated by \cite{?} using a non-astro... iv) ...  
%The difference between any two numbers in a given column gives the log Bayes factor for comparing the two models.
%QUESTION: Would it be better to give the log BF compared to a particular model (the best? the worst?).
%ADD minimum value so that can reconstruct if wanted.
%}
%\label{Tab:EvidenceSS}
%\end{center}
%\end{table}
%
%
%\begin{table}[t]
%\begin{center}
%\begin{tabular}{ l l  c c  c c }
%\toprule
%\multicolumn{2}{c}{Model} & \multicolumn{4}{c}{Dataset} \\
%%\cline{3-6}
%& & SM91-u & SM91-f & ODP677-u & ODP677-f\\
%\midrule
%SM91 & Forced & $66.2$ & $94.7$ & $56.6$ & $64.6$ \\
% & Unforced & $69.2$ & $42.3$ & $61.1$ & $41.9$ \\
%T06 & Forced & $47.3$ & $70.0$ & $58.8$ & $ 68.3$  \\
% & Unforced & $50.8$ & $33.3$ & $65.0$ & $49.5$  \\ 
%PP12 & Forced & $19.5$ & $42.2$ & $51.1$ & $78.9$  \\
%\bottomrule
%\end{tabular}
%\caption{WARNING: rounding errors here as I've taken Jake's Z value to two dp and logged it.
%The log model evidences  for each model and dataset. The four datasets are i) SM91-u: data simulated from an unforced version of SM91 ii) SM91-f: data simulated from a forced version of SM91 iii) ODP677-u: real data from the ocean drilling programme dated by \cite{?} using a non-astro... iv) ...  
%The difference between any two numbers in a given column gives the log Bayes factor for comparing the two models.
%QUESTION: Would it be better to give the log BF compared to a particular model (the best? the worst?).
%}
%\label{Tab:Evidence}
%\end{center}
%\end{table}
%


\clearpage

\begin{figure}
\centering
\includegraphics[width=\textwidth]{ODP677Plot.pdf}
\caption{
JAKE - Please can you make the axis labels larger?
Observed $\delta^{18}\mbox{O}$ from ODP677 \cite{Shackleton1990} corresponding to the past 780 kyr.
This dataset has been dated without the use of orbital tuning  \cite{Huybers2007}.}
\label{Fig:Data}
\end{figure}



\clearpage

\begin{figure}
\centering
\includegraphics[width=\textwidth]{MSSSPE.pdf}\\\vspace{24pt}
\caption{
JAKE - Please can you make the axis labels larger?
Marginal posterior distributions for the parameters of the forced SM91 model when fit to the  SM91-f dataset.
Vertical lines show the parameter values used to generate the data, and dashed lines represent the prior distribution. 
}
\label{Fig:PosteriorSS}
\end{figure}


\clearpage

\begin{figure}
\centering
\includegraphics[width=\textwidth]{LR04677SM91.pdf}
\caption{
JAKE - Please can you make the axis labels larger?
Marginal posterior distributions for the fully forced SM91 model on ODP677-f. Dashed lines represent the prior distributions, and solid lines the posteriors. 
The prior distributions used are given in Table ref{Tab:Priors}}
\label{Fig:PosteriorODP}
\end{figure}



\clearpage

\begin{figure}
\centering
\includegraphics[width=\textwidth]{ForcingComparison.pdf}
\caption{
JAKE - Please can you make the axis labels larger?
Posterior density plot of the ratio of the orbital scaling terms for the SM91 model (black line), and T06 model (red line).}
\label{Fig:AFRatio}
\end{figure}


\clearpage

\begin{figure}
\centering
\includegraphics[scale=0.15]{CompactionSS01X01.pdf}\\
\includegraphics[scale=0.15]{CompactionSS01X02.pdf}
\caption{JAKE: These are the wrong figures - could you put in the correct figure. Add the truth on, and the data on $x_1$.   }
\label{Fig:Trajectories}
\end{figure}


%
%\begin{table}[t]
%\begin{center}
%\begin{tabular}{| l l | c c | c c |}
%
%\hline
%\multicolumn{2}{|c|}{Model} & \multicolumn{4}{|c|}{Evidence} \\
%\cline{3-6}
%& & SM91-u & SM91-f & ODP677-u & ODP677-f\\
%\hline
%SM91 & Forced & $5.6 \times 10^{28}$ & $1.4 \times 10^{41}$ & $4.0 \times 10^{24}$ & $1.1 \times 10^{28}$ \\
% & Unforced & $1.1 \times 10^{30}$ & $2.4 \times 10^{18}$ & $3.5 \times 10^{26}$ & $1.6 \times 10^{18}$ \\
%T06 & Forced & $3.6 \times 10^{20}$ & $2.6 \times 10^{30}$ & $3.3 \times 10^{25}$ & $4.5 \times 10^{29}$  \\
% & Unforced & $1.1 \times 10^{22}$ & $2.9 \times 10^{14}$ & $1.7 \times 10^{28}$ & $3.3 \times 10^{21}$  \\ 
%PP12 & Forced & $2.8 \times 10^{8}$ & $2.1 \times 10^{18}$ & $1.5 \times 10^{22}$ & $1.8 \times 10^{34}$  \\
%\hline
%\end{tabular}
%\caption{The model evidence for each model over different datasets.}
%\label{Tab:Evidence}
%\end{center}
%\end{table}
%




\end{document}
